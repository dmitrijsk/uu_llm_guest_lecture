{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "733e6ff4-a77d-4084-90b6-ebd783eb442e",
   "metadata": {},
   "source": [
    "**Note:** This notebook uses OpenAI's models (for chat completion and embeddings), which require a paid OpenAI account. You can replace these models with open-source alternatives. For instance, the [Instructor package](https://python.useinstructor.com/) supports various models. Similarly, [LangChain](https://python.langchain.com/v0.1/docs/integrations/llms/) also supports other models. If you're open to spending a bit on OpenAI's models, here’s the [pricing](https://openai.com/api/pricing/). Learning their API can also be a valuable experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460923dd-8331-447c-9766-b4f919ab3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff3a1f-8fd0-4151-a16e-8ebff4d7a26d",
   "metadata": {},
   "source": [
    "# Structured output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0849c8a-44e0-403e-840d-0a839b0fc79d",
   "metadata": {},
   "source": [
    "## Regular output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d970161-a9cc-44e5-86a3-b9550e69c835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spider-Man is a fictional superhero created by writer Stan Lee and artist Steve Ditko for Marvel Comics. His real name is Peter Parker, a high school student who gains superhuman abilities after being bitten by a radioactive spider. \n",
      "\n",
      "Spider-Man is known for his red and blue costume with a web design, as well as his ability to crawl on walls, shoot webs from his wrists, and have a \"spider-sense\" that warns him of danger. He is also known for his wit and sense of humor, often cracking jokes during battles with villains.\n",
      "\n",
      "Peter Parker juggles his responsibilities as Spider-Man with his personal life, often struggling with the balance between his superhero duties and his relationships. He is often seen as a symbol of empowerment and responsibility, as he uses his powers to protect New York City from various threats while also dealing with his own internal struggles and insecurities.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Describe Spider man\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b9614-c533-409b-85cb-236c15eaf44a",
   "metadata": {},
   "source": [
    "It's impossible to have a reliable automation based on LLM's output if it's unstructured. Pydantic data classes to the rescue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c0a76b-2b33-46bc-96a6-18d5bf2cb47d",
   "metadata": {},
   "source": [
    "For more information, [OpenAI's API reference for chat completion](https://platform.openai.com/docs/api-reference/chat/create)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e833a8ad-a978-46ad-96ba-983f6d3ea60b",
   "metadata": {},
   "source": [
    "## Pydantic data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c3b79c-95eb-47bf-9d2a-d8e84169cc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"description\": \"Details of a character\",\n",
      "    \"properties\": {\n",
      "        \"name\": {\n",
      "            \"title\": \"Name\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"real_name\": {\n",
      "            \"title\": \"Real Name\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"age\": {\n",
      "            \"title\": \"Age\",\n",
      "            \"type\": \"integer\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"name\",\n",
      "        \"real_name\",\n",
      "        \"age\"\n",
      "    ],\n",
      "    \"title\": \"Character\",\n",
      "    \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Character(BaseModel):\n",
    "    \"\"\"Details of a character\"\"\"\n",
    "\n",
    "    name: str\n",
    "    real_name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "schema = Character.model_json_schema()\n",
    "print(json.dumps(schema, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017340b-69e3-45fd-b4a3-4fb2c5482cfe",
   "metadata": {},
   "source": [
    "About [Pydantic data model](https://docs.pydantic.dev/latest/concepts/models/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bfe917-aecf-495e-8e83-a99b73de0a83",
   "metadata": {},
   "source": [
    "## Structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ea8eb79-252d-452c-b03d-d918fbb207e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"name\": \"Spider Man\",\n",
      "    \"real_name\": \"Peter Parker\",\n",
      "    \"age\": 24\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "client = instructor.patch(OpenAI())\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Describe Spider man\"},\n",
    "    ],\n",
    "    response_model=Character,\n",
    ")\n",
    "\n",
    "print(response.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5630d2f-ade2-41ac-a518-32fe6e6ece7c",
   "metadata": {},
   "source": [
    "Learn more about structured output with LLMs: https://github.com/wandb/edu/tree/main/llm-structured-extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeaa16b-977a-40bd-a1a5-1eff5ee228c2",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e7ea1-6ad8-4ac2-b494-72ffb4d68188",
   "metadata": {},
   "source": [
    "Based on https://aiplanet.com/learn/rag-agents-bootcamp/module-3/2439/notebook-simple-rag-using-langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa976d-b1bd-40e3-b463-2f816a3d1f22",
   "metadata": {},
   "source": [
    "## Load and split the PDF document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837017b7-9240-46c5-b5d5-4ecf1d959884",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install langchain langchain_community pypdf fastembed chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "856c08d3-33d8-4875-ab73-f58e994162df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "\n",
    "# Book: https://www.manning.com/books/build-a-large-language-model-from-scratch\n",
    "loader = PyPDFLoader(\"uu/Build_a_Large_Language_Model_(From_Scrat.pdf\")\n",
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9394d4-d57f-4ccb-808b-5a1fd854f5aa",
   "metadata": {},
   "source": [
    "I.e., 370 pages of a PDF were read. Let's check one of the page 17:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a30a859-e7f9-4387-959b-dd59c8890d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xvabout this book\n",
      "Build a Large Language Model (From Scratch)  was written to help you understand and\n",
      "c r e at e  y o ur  o w n G P T- l ik e  l ar g e  la ng u ag e  m o d e ls  ( L L M s )  f r o m  t h e  gr o u nd  u p.  I tbegins by focusing on the fu ndamentals of working with text data and coding atten-\n",
      "tion mechanisms and then guides you through implementing a complete GPT\n",
      "model from scratch. The book then cove rs the pretraining mechanism as well as\n",
      "fine-tuning for specific tasks such as text classification and following instructions. By\n",
      "the end of this book, you’ll have a deep understanding of how LLMs work and the\n",
      "skills to build your own models. While the models you’ll create are smaller in scalecompared to the large founda tional models, they use the same concepts and serve\n",
      "as powerful educational tools to grasp th e core mechanisms and techniques used in\n",
      "building state-of-the-art LLMs.\n",
      "Who should read this book\n",
      "Build a Large Language  Model (From Scratch)  is for machine learning enthusiasts, engi-\n",
      "neers, researchers, students , and practitioners who want to gain a deep understand-\n",
      "ing of how LLMs work and learn to buil d their own models from scratch. Both\n",
      "beginners and experienced developers will be able to use their existing skills and\n",
      "knowledge to grasp the co ncepts and techniques used in creating LLMs.\n",
      " What sets this book apar t is its comprehensive coverage of the entire process of\n",
      "building LLMs, from working with datasets  to implementing the model architecture,\n",
      "pretraining on unlabeled data, and fine-tuning for specific tasks. As of this writing, no\n",
      "Licensed to Dmitrijs Kass <dmitrijs.kass@gmail.com>\n"
     ]
    }
   ],
   "source": [
    "print(data[16].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57b940e-c7ed-4ff8-a12b-f270b84ea6cd",
   "metadata": {},
   "source": [
    "PDF pages are too large and need to be split into chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c0ebe59-8bf8-43be-b671-5ff3b4ed2e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1717"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "chunk_size = 512,\n",
    "chunk_overlap = 50,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebe581f1-ea30-4a1b-b13e-c46accc4d28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "put text. In a translation task, for example, the encoder would encode the text fromthe source language into vectors, and the decoder would decode these vectors to gen-\n",
      "erate text in the target language. Both th e encoder and decoder consist of many layers\n",
      "connected by a so-called self-attention mechanism. You may have many questionsregarding how the inputs are preprocessed an d encoded. These will be addressed in a\n",
      "step-by-step implementation in subsequent chapters.\n"
     ]
    }
   ],
   "source": [
    "print(chunks[100].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d62dd2-32b2-4ae0-a9ce-0f1cfb2c5b84",
   "metadata": {},
   "source": [
    "## Embeddings and a vector database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99573661-018c-44fc-95f1-1efab431e822",
   "metadata": {},
   "source": [
    "The next step is to embed all of these chunks and add them to a vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d52a4cb3-a63e-4a99-8976-1023dc13c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd869f5-fc43-470e-b604-a16b442c58a8",
   "metadata": {},
   "source": [
    "Text run for a single chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d0f75d1-d643-4d98-a2d1-636f731f8fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = embedding_model.embed_documents(chunks[37].page_content)\n",
    "len(embedding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf0492-f1aa-4787-b43c-ca5d047a7e60",
   "metadata": {},
   "source": [
    "This is the size of the embedding. Read more [here](https://openai.com/index/new-embedding-models-and-api-updates/). Let's see the first 10 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b2359d5-6d12-4e33-acca-306dc4adeb93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.013922779820859432,\n",
       " -0.014787135645747185,\n",
       " 0.002779236761853099,\n",
       " -0.030584903433918953,\n",
       " -0.03484019264578819,\n",
       " 0.010199400596320629,\n",
       " -0.0164626557379961,\n",
       " -0.01055844034999609,\n",
       " -0.004241993185132742,\n",
       " -0.03172851353883743]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea0346d-f041-4999-9bb3-22265f062b14",
   "metadata": {},
   "source": [
    "Create a vector database, embed all chunks and add them to the vector database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db368654-0c5f-4b55-907a-f66c55551e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "db = Chroma.from_documents(chunks, embedding_model, persist_directory=\"./uu/chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af9349-4ec2-4641-b7dc-d870eea2c175",
   "metadata": {},
   "source": [
    "## Test run: retrieve relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c23b71c-05d0-4bd7-a059-577f7c38ff94",
   "metadata": {},
   "source": [
    "Define User Query:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4c96753-3756-43e7-a3f2-7f6fa5a5cbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who should read the LLM from scratch book?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7563359a-1983-4077-8f20-eda27cd1ef97",
   "metadata": {},
   "source": [
    "Let's retrieve 4 most similar documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8edb0cd4-4c13-4312-a5ef-0f84265bfe3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Page 16\n",
      "Who should read this book\n",
      "Build a Large Language  Model (From Scratch)  is for machine learning enthusiasts, engi-\n",
      "neers, researchers, students , and practitioners who want to gain a deep understand-\n",
      "ing of how LLMs work and learn to buil d their own models from scratch. Both\n",
      "beginners and experienced developers will be able to use their existing skills and\n",
      "knowledge to grasp the co ncepts and techniques used in creating LLMs.\n",
      "\n",
      "Document 2:\n",
      "Page 16\n",
      "Who should read this book\n",
      "Build a Large Language  Model (From Scratch)  is for machine learning enthusiasts, engi-\n",
      "neers, researchers, students , and practitioners who want to gain a deep understand-\n",
      "ing of how LLMs work and learn to buil d their own models from scratch. Both\n",
      "beginners and experienced developers will be able to use their existing skills and\n",
      "knowledge to grasp the co ncepts and techniques used in creating LLMs.\n",
      "\n",
      "Document 3:\n",
      "Page 16\n",
      "Who should read this book\n",
      "Build a Large Language  Model (From Scratch)  is for machine learning enthusiasts, engi-\n",
      "neers, researchers, students , and practitioners who want to gain a deep understand-\n",
      "ing of how LLMs work and learn to buil d their own models from scratch. Both\n",
      "beginners and experienced developers will be able to use their existing skills and\n",
      "knowledge to grasp the co ncepts and techniques used in creating LLMs.\n",
      "\n",
      "Document 4:\n",
      "Page 16\n",
      "fine-tuning for specific tasks such as text classification and following instructions. By\n",
      "the end of this book, you’ll have a deep understanding of how LLMs work and the\n",
      "skills to build your own models. While the models you’ll create are smaller in scalecompared to the large founda tional models, they use the same concepts and serve\n",
      "as powerful educational tools to grasp th e core mechanisms and techniques used in\n",
      "building state-of-the-art LLMs.\n",
      "Who should read this book\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = db.similarity_search(query, k=4)\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(f\"Page {doc.metadata['page']}\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378de7a-385f-4958-91d6-843135dc110b",
   "metadata": {},
   "source": [
    "## Create a simple RAG solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1729feae-8b81-4ece-a401-a57a5b82ab63",
   "metadata": {},
   "source": [
    "Initialize the retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "324bcd22-312d-4e45-957a-c05a9f712842",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\", # Maximum Marginal Relevance, e.g., https://docs.llamaindex.ai/en/stable/examples/vector_stores/SimpleIndexDemoMMR/\n",
    "    search_kwargs={'k': 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d641d81f-64ef-401d-b879-a289607a2644",
   "metadata": {},
   "source": [
    "Define LLM and Chain Components:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd03d1d4-482d-47c3-8c25-2aef8aa0820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52b6a4b2-3b48-45de-8812-8f1bc1d25339",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "<s>\n",
    "[INST]\n",
    "You are an AI Assistant that follows instructions extremely well.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in CONTEXT\n",
    "[/INST]\n",
    "\n",
    "CONTEXT: {context}\n",
    "</s>\n",
    "\n",
    "[INST]\n",
    "{query}\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21bc8cc5-7d3f-48ee-993e-24133717b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee8a7209-ed9a-4dce-9ff5-750180535808",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "{\"context\": retriever, \"query\": RunnablePassthrough()}\n",
    "| prompt\n",
    "| llm\n",
    "| output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67ef2dc7-039f-491a-bd25-332da8ca94ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book \"Build a Large Language Model (From Scratch)\" is intended for machine learning enthusiasts, engineers, researchers, students, and practitioners who want to gain a deep understanding of how LLMs work and learn to build their own models from scratch. Both beginners and experienced developers will be able to use their existing skills and knowledge to grasp the concepts and techniques used in creating LLMs.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ca90140-edb2-4313-8f5c-2aca1d236821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The architecture of GPT is discussed on page 30 of the document. It states that the GPT architecture is designed for tasks that require generating texts, including machine translation, text summarization, fiction writing, and writing computer code. It also mentions that GPT models are primarily designed and trained to perform text completion tasks and show remarkable versatility in their capabilities, being adept at executing both zero-shot and few-shot learning tasks.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"Which page talks about the architecture of GPT and what does it say?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd17099-94f8-4701-b635-89bb5ce4ee41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
